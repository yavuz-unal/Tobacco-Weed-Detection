# Import'lar
import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from transformers import DetrImageProcessor, DetrForObjectDetection
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

print("âœ… Kurulum tamamlandÄ±!")

# =============================================================================
# BLOK 2: Drive BaÄŸlantÄ±sÄ± ve Veri YÃ¼kleme
# =============================================================================

# Veri yollarÄ±nÄ± tanÄ±mla
IMAGE_DIR = "/content/drive/MyDrive/tutun/tutun"  # Resim klasÃ¶rÃ¼
ANNOTATION_FILE = "/content/drive/MyDrive/Tobacco_Project/dataset/labels_my-project-name_2025-06-16-11-20-57.json"  # JSON dosyasÄ±

print(f"ğŸ–¼ï¸ Image directory: {IMAGE_DIR}")
print(f"ğŸ“ Annotation file: {ANNOTATION_FILE}")

# Dosya kontrolÃ¼
if os.path.exists(ANNOTATION_FILE):
    print("âœ… Annotation dosyasÄ± bulundu!")
else:
    print("âŒ Annotation dosyasÄ± bulunamadÄ±! Yolu kontrol edin.")

if os.path.exists(IMAGE_DIR):
    image_count = len([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    print(f"âœ… {image_count} adet resim bulundu!")
else:
    print("âŒ Resim klasÃ¶rÃ¼ bulunamadÄ±! Yolu kontrol edin.")

!pip install ultralytics

# =============================================================================
# BLOK 3: JSON Veri Analizi ve SÄ±nÄ±f Bilgilerini Ã‡Ä±karma
# =============================================================================

import json
from collections import Counter

def analyze_json_data(annotation_file):
    """JSON dosyasÄ±nÄ± analiz et ve sÄ±nÄ±f bilgilerini Ã§Ä±kar"""
    with open(annotation_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print("ğŸ“Š JSON Veri Analizi:")
    print(f"Total images: {len(data.get('images', []))}")
    print(f"Total annotations: {len(data.get('annotations', []))}")
    print(f"Categories: {len(data.get('categories', []))}")

    # Kategori bilgilerini Ã§Ä±kar
    categories = data.get('categories', [])
    category_dict = {cat['id']: cat['name'] for cat in categories}

    print("\nğŸ·ï¸ Tespit edilecek sÄ±nÄ±flar:")
    for cat_id, cat_name in category_dict.items():
        print(f"  {cat_id}: {cat_name}")

    # Annotation sayÄ±larÄ±nÄ± say
    annotations = data.get('annotations', [])
    category_counts = Counter([ann['category_id'] for ann in annotations])

    print("\nğŸ“ˆ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    for cat_id, count in category_counts.items():
        cat_name = category_dict.get(cat_id, 'Unknown')
        print(f"  {cat_name}: {count} annotation")

    return data, category_dict

# JSON verisini analiz et
if os.path.exists(ANNOTATION_FILE):
    coco_data, class_names = analyze_json_data(ANNOTATION_FILE)
else:
    print("âŒ JSON dosyasÄ± bulunamadÄ±!")
import shutil

# BLOK 4: COCO FormatÄ±ndan YOLO FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼rme
# =============================================================================

def convert_coco_to_yolo(coco_data, image_dir, output_dir):
    """COCO formatÄ±ndaki veriyi YOLO formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r"""

    # Ã‡Ä±kÄ±ÅŸ klasÃ¶rlerini oluÅŸtur
    images_dir = os.path.join(output_dir, 'images')
    labels_dir = os.path.join(output_dir, 'labels')

    os.makedirs(images_dir, exist_ok=True)
    os.makedirs(labels_dir, exist_ok=True)

    # Image ID'den filename'e mapping
    images_info = {img['id']: img for img in coco_data['images']}

    # Her resim iÃ§in YOLO formatÄ±nda label dosyasÄ± oluÅŸtur
    for image_info in coco_data['images']:
        image_id = image_info['id']
        filename = image_info['file_name']
        width = image_info['width']
        height = image_info['height']

        # Bu resme ait annotationlarÄ± bul
        image_annotations = [ann for ann in coco_data['annotations']
                           if ann['image_id'] == image_id]

        # YOLO formatÄ±nda label dosyasÄ± oluÅŸtur
        label_filename = os.path.splitext(filename)[0] + '.txt'
        label_path = os.path.join(labels_dir, label_filename)

        with open(label_path, 'w') as f:
            for ann in image_annotations:
                # COCO bbox: [x, y, width, height] (top-left corner)
                # YOLO bbox: [center_x, center_y, width, height] (normalized)

                x, y, w, h = ann['bbox']

                # Normalize coordinates
                center_x = (x + w/2) / width
                center_y = (y + h/2) / height
                norm_w = w / width
                norm_h = h / height

                # Class ID (YOLO 0-indexed olacak ÅŸekilde)
                class_id = ann['category_id'] - 1  # COCO 1-indexed, YOLO 0-indexed

                f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n")

        # Resmi kopyala (opsiyonel)
        src_image_path = os.path.join(image_dir, filename)
        dst_image_path = os.path.join(images_dir, filename)

        if os.path.exists(src_image_path):
            import shutil
            shutil.copy2(src_image_path, dst_image_path)

# YOLO formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
OUTPUT_DIR = "/content/drive/MyDrive/yolo_dataset"
print("ğŸ”„ COCO formatÄ±ndan YOLO formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")

if 'coco_data' in locals():
    convert_coco_to_yolo(coco_data, IMAGE_DIR, OUTPUT_DIR)
    print(f"âœ… DÃ¶nÃ¼ÅŸtÃ¼rme tamamlandÄ±! Dosyalar: {OUTPUT_DIR}")
else:
    print("âŒ COCO verisi yÃ¼klenemedi!")

# =============================================================================
# BLOK 5: Train/Validation Split ve Dataset HazÄ±rlama
# =============================================================================

def create_train_val_split(output_dir, train_ratio=0.8):
    """Train ve validation setlerini ayÄ±r"""

    images_dir = os.path.join(output_dir, 'images')
    labels_dir = os.path.join(output_dir, 'labels')

    # TÃ¼m resim dosyalarÄ±nÄ± listele
    image_files = [f for f in os.listdir(images_dir)
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    # Train/Val split
    train_images, val_images = train_test_split(
        image_files,
        train_size=train_ratio,
        random_state=42
    )

    print(f"ğŸ“Š Dataset split:")
    print(f"  Training images: {len(train_images)}")
    print(f"  Validation images: {len(val_images)}")

    # Train ve val klasÃ¶rlerini oluÅŸtur
    for split_name, image_list in [('train', train_images), ('val', val_images)]:
        split_images_dir = os.path.join(output_dir, split_name, 'images')
        split_labels_dir = os.path.join(output_dir, split_name, 'labels')

        os.makedirs(split_images_dir, exist_ok=True)
        os.makedirs(split_labels_dir, exist_ok=True)

        # DosyalarÄ± taÅŸÄ±
        for img_file in image_list:
            # Resim dosyasÄ±
            src_img = os.path.join(images_dir, img_file)
            dst_img = os.path.join(split_images_dir, img_file)

            # Label dosyasÄ±
            label_file = os.path.splitext(img_file)[0] + '.txt'
            src_label = os.path.join(labels_dir, label_file)
            dst_label = os.path.join(split_labels_dir, label_file)

            if os.path.exists(src_img):
                shutil.move(src_img, dst_img)
            if os.path.exists(src_label):
                shutil.move(src_label, dst_label)

    return len(train_images), len(val_images)

# Train/Val split yap
if os.path.exists(OUTPUT_DIR):

# BLOK 6: YAML KonfigÃ¼rasyon DosyasÄ± OluÅŸturma
# =============================================================================

def create_yaml_config(output_dir, class_names):
    """YOLOv8 iÃ§in YAML konfigÃ¼rasyon dosyasÄ± oluÅŸtur"""

    yaml_content = f"""# Yabani Ot Tespiti Dataset KonfigÃ¼rasyonu
path: {output_dir}  # dataset root dir
train: train/images  # train images (relative to 'path')
val: val/images  # val images (relative to 'path')

# Classes
nc: {len(class_names)}  # number of classes
names: {list(class_names.values())}  # class names
"""

    yaml_path = os.path.join(output_dir, 'dataset.yaml')
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)

    print(f"ğŸ“ YAML konfigÃ¼rasyonu oluÅŸturuldu: {yaml_path}")
    print("\nğŸ“‹ Dataset konfigÃ¼rasyonu:")
    print(yaml_content)

    return yaml_path

# YAML dosyasÄ± oluÅŸtur
if 'class_names' in locals() and os.path.exists(OUTPUT_DIR):
    yaml_path = create_yaml_config(OUTPUT_DIR, class_names)
else:
    print("âŒ SÄ±nÄ±f bilgileri veya dataset klasÃ¶rÃ¼ bulunamadÄ±!")

print("\nğŸ¯ Dataset hazÄ±rlama iÅŸlemi tamamlandÄ±!")
print("ğŸ“‚ KlasÃ¶r yapÄ±sÄ±:")
print(f"  {OUTPUT_DIR}/")
print(f"  â”œâ”€â”€ train/")
print(f"  â”‚   â”œâ”€â”€ images/")
print(f"  â”‚   â””â”€â”€ labels/")
print(f"  â”œâ”€â”€ val/")
print(f"  â”‚   â”œâ”€â”€ images/")
print(f"  â”‚   â””â”€â”€ labels/")
print(f"  â””â”€â”€ dataset.yaml")
    train_count, val_count = create_train_val_split(OUTPUT_DIR)
    print("âœ… Train/Validation split tamamlandÄ±!")
else:
    print("âŒ YOLO dataset klasÃ¶rÃ¼ bulunamadÄ±!")

# =============================================================================
# BLOK 7: YOLOv8 Kurulumu ve Model HazÄ±rlama
# =============================================================================

# YOLOv8 kurulumu (Colab'da Ã§alÄ±ÅŸtÄ±rÄ±n)
print("ğŸ“¦ YOLOv8 kuruluyor...")
# !pip install ultralytics

# YOLOv8 import
from ultralytics import YOLO
import yaml

# Model seÃ§imi (boyuta gÃ¶re seÃ§ebilirsiniz)
MODEL_SIZE = 'n'  # 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (extra large)
model_name = f'yolov8{MODEL_SIZE}.pt'

print(f"ğŸ¤– Model yÃ¼kleniyor: {model_name}")
model = YOLO(model_name)  # Pretrained model yÃ¼kle

print("âœ… YOLOv8 model hazÄ±r!")

# =============================================================================
# BLOK 8: Model EÄŸitimi
# =============================================================================

def train_yolov8_model(model, yaml_path, epochs=100, imgsz=640, batch_size=16):
    """YOLOv8 modelini eÄŸit"""

    print("ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...")
    print(f"ğŸ“Š EÄŸitim parametreleri:")
    print(f"  Epochs: {epochs}")
    print(f"  Image size: {imgsz}")
    print(f"  Batch size: {batch_size}")

    # EÄŸitimi baÅŸlat
    results = model.train(
        data=yaml_path,           # Dataset YAML dosyasÄ±
        epochs=epochs,            # Epoch sayÄ±sÄ±
        imgsz=imgsz,             # Resim boyutu
        batch=batch_size,        # Batch boyutu
        patience=10,             # Early stopping patience
        save=True,               # Model kaydet
        device='0' if torch.cuda.is_available() else 'cpu',  # GPU kullan
        workers=2,               # DataLoader worker sayÄ±sÄ±
        project='yolo_weed_detection',  # Proje klasÃ¶rÃ¼
        name='weed_model',       # Model adÄ±
        verbose=True             # DetaylÄ± log
    )

    print("âœ… Model eÄŸitimi tamamlandÄ±!")
    return results

# Model eÄŸitimini baÅŸlat
if 'yaml_path' in locals() and 'model' in locals():
    print("â³ EÄŸitim baÅŸlatÄ±lÄ±yor... (Bu iÅŸlem uzun sÃ¼rebilir)")
    training_results = train_yolov8_model(
        model=model,
        yaml_path=yaml_path,
        epochs=100,      # Ä°htiyacÄ±nÄ±za gÃ¶re ayarlayÄ±n
        imgsz=640,       # Resim boyutu
        batch_size=16    # Batch boyutu (GPU'nuz sÄ±nÄ±rlÄ±ysa azaltÄ±n)
    )
else:
    print("âŒ Model veya YAML dosyasÄ± bulunamadÄ±!")
