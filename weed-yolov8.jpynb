# Imports
import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from transformers import DetrImageProcessor, DetrForObjectDetection
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

print("‚úÖ Installation completed!")

# =============================================================================
# BLOCK 2: Drive Connection and Data Loading
# =============================================================================

# Define data paths
IMAGE_DIR = "/content/drive/MyDrive/tutun/tutun"  # Image folder
ANNOTATION_FILE = "/content/drive/MyDrive/Tobacco_Project/dataset/labels_my-project-name_2025-06-16-11-20-57.json"  # JSON file

print(f"üñºÔ∏è Image directory: {IMAGE_DIR}")
print(f"üìù Annotation file: {ANNOTATION_FILE}")

# File check
if os.path.exists(ANNOTATION_FILE):
    print("‚úÖ Annotation file found!")
else:
    print("‚ùå Annotation file not found! Check the path.")

if os.path.exists(IMAGE_DIR):
    image_count = len([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    print(f"‚úÖ {image_count} images found!")
else:
    print("‚ùå Image folder not found! Check the path.")

!pip install ultralytics

# =============================================================================
# BLOCK 3: JSON Data Analysis and Class Information Extraction
# =============================================================================

import json
from collections import Counter

def analyze_json_data(annotation_file):
    """Analyze JSON file and extract class information"""
    with open(annotation_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print("üìä JSON Data Analysis:")
    print(f"Total images: {len(data.get('images', []))}")
    print(f"Total annotations: {len(data.get('annotations', []))}")
    print(f"Categories: {len(data.get('categories', []))}")

    # Extract category information
    categories = data.get('categories', [])
    category_dict = {cat['id']: cat['name'] for cat in categories}

    print("\nüè∑Ô∏è Classes to be detected:")
    for cat_id, cat_name in category_dict.items():
        print(f"  {cat_id}: {cat_name}")

    # Count annotations
    annotations = data.get('annotations', [])
    category_counts = Counter([ann['category_id'] for ann in annotations])

    print("\nüìà Class distribution:")
    for cat_id, count in category_counts.items():
        cat_name = category_dict.get(cat_id, 'Unknown')
        print(f"  {cat_name}: {count} annotations")

    return data, category_dict

# Analyze JSON data
if os.path.exists(ANNOTATION_FILE):
    coco_data, class_names = analyze_json_data(ANNOTATION_FILE)
else:
    print("‚ùå JSON file not found!")
import shutil

# BLOCK 4: Convert COCO Format to YOLO Format
# =============================================================================

def convert_coco_to_yolo(coco_data, image_dir, output_dir):
    """Convert COCO format data to YOLO format"""

    # Create output folders
    images_dir = os.path.join(output_dir, 'images')
    labels_dir = os.path.join(output_dir, 'labels')

    os.makedirs(images_dir, exist_ok=True)
    os.makedirs(labels_dir, exist_ok=True)

    # Image ID to filename mapping
    images_info = {img['id']: img for img in coco_data['images']}

    # Create YOLO format label files for each image
    for image_info in coco_data['images']:
        image_id = image_info['id']
        filename = image_info['file_name']
        width = image_info['width']
        height = image_info['height']

        # Find annotations for this image
        image_annotations = [ann for ann in coco_data['annotations']
                           if ann['image_id'] == image_id]

        # Create YOLO format label file
        label_filename = os.path.splitext(filename)[0] + '.txt'
        label_path = os.path.join(labels_dir, label_filename)

        with open(label_path, 'w') as f:
            for ann in image_annotations:
                # COCO bbox: [x, y, width, height] (top-left corner)
                # YOLO bbox: [center_x, center_y, width, height] (normalized)

                x, y, w, h = ann['bbox']

                # Normalize coordinates
                center_x = (x + w/2) / width
                center_y = (y + h/2) / height
                norm_w = w / width
                norm_h = h / height

                # Class ID (YOLO will be 0-indexed)
                class_id = ann['category_id'] - 1  # COCO 1-indexed, YOLO 0-indexed

                f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n")

        # Copy image (optional)
        src_image_path = os.path.join(image_dir, filename)
        dst_image_path = os.path.join(images_dir, filename)

        if os.path.exists(src_image_path):
            import shutil
            shutil.copy2(src_image_path, dst_image_path)

# Convert to YOLO format
OUTPUT_DIR = "/content/drive/MyDrive/yolo_dataset"
print("üîÑ Converting from COCO format to YOLO format...")

if 'coco_data' in locals():
    convert_coco_to_yolo(coco_data, IMAGE_DIR, OUTPUT_DIR)
    print(f"‚úÖ Conversion completed! Files: {OUTPUT_DIR}")
else:
    print("‚ùå COCO data could not be loaded!")

# =============================================================================
# BLOCK 5: Train/Validation Split and Dataset Preparation
# =============================================================================

def create_train_val_split(output_dir, train_ratio=0.8):
    """Split train and validation sets"""

    images_dir = os.path.join(output_dir, 'images')
    labels_dir = os.path.join(output_dir, 'labels')

    # List all image files
    image_files = [f for f in os.listdir(images_dir)
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    # Train/Val split
    train_images, val_images = train_test_split(
        image_files,
        train_size=train_ratio,
        random_state=42
    )

    print(f"üìä Dataset split:")
    print(f"  Training images: {len(train_images)}")
    print(f"  Validation images: {len(val_images)}")

    # Create train and val folders
    for split_name, image_list in [('train', train_images), ('val', val_images)]:
        split_images_dir = os.path.join(output_dir, split_name, 'images')
        split_labels_dir = os.path.join(output_dir, split_name, 'labels')

        os.makedirs(split_images_dir, exist_ok=True)
        os.makedirs(split_labels_dir, exist_ok=True)

        # Move files
        for img_file in image_list:
            # Image file
            src_img = os.path.join(images_dir, img_file)
            dst_img = os.path.join(split_images_dir, img_file)

            # Label file
            label_file = os.path.splitext(img_file)[0] + '.txt'
            src_label = os.path.join(labels_dir, label_file)
            dst_label = os.path.join(split_labels_dir, label_file)

            if os.path.exists(src_img):
                shutil.move(src_img, dst_img)
            if os.path.exists(src_label):
                shutil.move(src_label, dst_label)

    return len(train_images), len(val_images)

# Create train/val split
if os.path.exists(OUTPUT_DIR):

# BLOCK 6: Create YAML Configuration File
# =============================================================================

def create_yaml_config(output_dir, class_names):
    """Create YAML configuration file for YOLOv8"""

    yaml_content = f"""# Weed Detection Dataset Configuration
path: {output_dir}  # dataset root dir
train: train/images  # train images (relative to 'path')
val: val/images  # val images (relative to 'path')

# Classes
nc: {len(class_names)}  # number of classes
names: {list(class_names.values())}  # class names
"""

    yaml_path = os.path.join(output_dir, 'dataset.yaml')
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)

    print(f"üìù YAML configuration created: {yaml_path}")
    print("\nüìã Dataset configuration:")
    print(yaml_content)

    return yaml_path

# Create YAML file
if 'class_names' in locals() and os.path.exists(OUTPUT_DIR):
    yaml_path = create_yaml_config(OUTPUT_DIR, class_names)
else:
    print("‚ùå Class information or dataset folder not found!")

print("\nüéØ Dataset preparation process completed!")
print("üìÇ Folder structure:")
print(f"  {OUTPUT_DIR}/")
print(f"  ‚îú‚îÄ‚îÄ train/")
print(f"  ‚îÇ   ‚îú‚îÄ‚îÄ images/")
print(f"  ‚îÇ   ‚îî‚îÄ‚îÄ labels/")
print(f"  ‚îú‚îÄ‚îÄ val/")
print(f"  ‚îÇ   ‚îú‚îÄ‚îÄ images/")
print(f"  ‚îÇ   ‚îî‚îÄ‚îÄ labels/")
print(f"  ‚îî‚îÄ‚îÄ dataset.yaml")
    train_count, val_count = create_train_val_split(OUTPUT_DIR)
    print("‚úÖ Train/Validation split completed!")
else:
    print("‚ùå YOLO dataset folder not found!")

# =============================================================================
# BLOCK 7: YOLOv8 Installation and Model Preparation
# =============================================================================

# YOLOv8 installation (run in Colab)
print("üì¶ Installing YOLOv8...")
# !pip install ultralytics

# YOLOv8 import
from ultralytics import YOLO
import yaml

# Model selection (you can choose by size)
MODEL_SIZE = 'n'  # 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (extra large)
model_name = f'yolov8{MODEL_SIZE}.pt'

print(f"ü§ñ Loading model: {model_name}")
model = YOLO(model_name)  # Load pretrained model

print("‚úÖ YOLOv8 model ready!")

# =============================================================================
# BLOCK 8: Model Training
# =============================================================================

def train_yolov8_model(model, yaml_path, epochs=100, imgsz=640, batch_size=16):
    """Train YOLOv8 model"""

    print("üöÄ Model training starting...")
    print(f"üìä Training parameters:")
    print(f"  Epochs: {epochs}")
    print(f"  Image size: {imgsz}")
    print(f"  Batch size: {batch_size}")

    # Start training
    results = model.train(
        data=yaml_path,           # Dataset YAML file
        epochs=epochs,            # Number of epochs
        imgsz=imgsz,             # Image size
        batch=batch_size,        # Batch size
        patience=10,             # Early stopping patience
        save=True,               # Save model
        device='0' if torch.cuda.is_available() else 'cpu',  # Use GPU
        workers=2,               # DataLoader worker count
        project='yolo_weed_detection',  # Project folder
        name='weed_model',       # Model name
        verbose=True             # Detailed logging
    )

    print("‚úÖ Model training completed!")
    return results

# Start model training
if 'yaml_path' in locals() and 'model' in locals():
    print("‚è≥ Starting training... (This process may take a long time)")
    training_results = train_yolov8_model(
        model=model,
        yaml_path=yaml_path,
        epochs=100,      # Adjust according to your needs
        imgsz=640,       # Image size
        batch_size=16    # Batch size (reduce if GPU is limited)
    )
else:
    print("‚ùå Model or YAML file not found!")
